{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pràctica 1 - El procés de l'aprenentatge automàtic:\n",
    "Fins ara hem treballat amb problemes de classificació de conjunts que tenien 2 classes i que estaven generats de manera artificial. En aquesta pràctica començarem a fer feina amb conjunts de dades reals que a més tenen més d'una classe.\n",
    "\n",
    "El procés d'aplicar tècniques d'aprenentatge és un procés que consta de cinc parts:\n",
    "\n",
    "- **Tractament de les dades: preparació del conjunt de dades, selecció de característiques, obtenció dels conjunts d'entrenament / test**.\n",
    "\n",
    "- **Selecció de la / les mètriques adients**.\n",
    "\n",
    "- **Selecció de la tècnica d'aprenentatge automàtic**.\n",
    "\n",
    "- **Avaluació del model**.\n",
    "\n",
    "- **Ajustament del model**.\n",
    "\n",
    "## Tractament de dades: selecció de característiques\n",
    "\n",
    "## Separació del conjunt de dades: validació creuada per avaluar el rendiment del nostre model\n",
    "\n",
    "### Mètode _holdout_\n",
    "\n",
    "Aquest mètode consisteix a separar el conjunt de dades en tres subconjunts diferents: entrenament, validació i _test_. El conjunt d'entrenament s'usa com és habitual, és a dir per entrenar els diferents models. El conjunt de validació s'usa per seleccionar el millor dels models. El conjunt de _test_, que no usem en cap cas durant el procés d'entrenament, ens servirà per obtenir una idea poc esbiaixada de la capacitat del model d'adaptar-se a noves mostres, sobre aquest conjunt de dades serà sobre el qual obtindrem les mètriques finals del model.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "![](imatges/holdout.png)\n",
    "\n",
    "Aquest mètode encara que senzill d'emprar té un desavantatge, el rendiment del model depèn de com hem fet la partició de les dades.\n",
    "\n",
    "### Mètode _K-Fold_\n",
    "\n",
    "Aquesta tècnica és més robusta, ja que repetim el mètode anterior _k_ vegades en _k_ subconjunts del conjunt d'entrenament, per tant, obtenim _k_ models i el mateix nombre de mesures de rendiment. El resultat final s'obtè amb la mitjana de cada una de les repeticions realitzades, d'aquesta manera els resultats depenen manco de les particions que realitzem.\n",
    "\n",
    "Aquesta tècnica normalment s'usa per obtenir els millors paràmetres del model a aplicar, es a dir trobar aquells paràmetres que maximitzen el rendiment de la mètrica que volem usar. Un cop que tenim els millors paràmetres, reentrenam el model emprant el conjunt d'entrenament complet i obtenim les mètriques amb el conjunt de _test_.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "<img src=\"imatges/Kfold.png\" alt=\"kfold\" width=\"600\"/>\n",
    "\n",
    "La pregunta que ens podem fer és: Com seleccionar aquest paràmetre _k_ de forma correcta?\n",
    "\n",
    "Finalment, existeix una variant d'aquesta tècnica anomenada _stratified k-fold_ en el que les proporcions entre classes es mantenen a cada una de les iteracions, això és important quan tenim problemes desbalancejats.\n",
    "\n",
    "## Selecció de mètriques\n",
    "\n",
    "Un cop entrenat el nostre model, tenim la necessitat d'avaluar els resultats obtinguts amb aquest amb alguna mesura que sigui objectiva. Les mesures que explicarem en aquesta secció es calculen a partir d'una matriu de confusió que ens permet guardar quatre mesures bàsiques a partir de considerar que una de les classes és la positiva i l'altra és la negativa.\n",
    "\n",
    "- _True Positives_ (TP): L'algorisme classifica una mostra de la classe positiva com a membre de la classe positiva.\n",
    "- _True Negatives_ (TN): L'algorisme classifica una mostra de la classe negativa com a membre de la classe negativa.\n",
    "- _False Positives_ (FP): L'algorisme classifica una mostra de la classe negativa com a membre de la classe positiva.\n",
    "- _False Negatives_ (FN): L'algorisme classifica una mostra de la classe positiva com a membre de la classe negativa.\n",
    "\n",
    "Podem observar la matriu de confusió en el següent esquema:\n",
    "\n",
    "![image](imatges/confusion_matrix.png \"font: Python Machine Learning\")\n",
    "\n",
    "Aquesta matriu es pot obtenir de manera senzilla usant la funció `confusion_matrix` de la llibreria [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion%20matrix#sklearn-metrics-confusion-matrix)\n",
    "i es pot visualitzar amb la funció [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html?highlight=confusion%20matrix#sklearn-metrics-confusionmatrixdisplay)\n",
    "\n",
    "A partir d'aquestes mesures de primer ordre en podem treure d'altres més completes com l'error o l'exactitud, també es coneix amb el nom de _Accuracy_.\n",
    "\n",
    "$$ Error = \\frac{FP+FN}{FP+FN+TP+TN}$$\n",
    "<br>\n",
    "$$ Exactitut = \\frac{TP+TN}{FP+FN+TP+TN} = 1 - Error$$\n",
    "\n",
    "Per altra banda, tenim les mesures Rati de Vertaders Positius (_True Positive Rate_, TPR) i la Ratio de Falsos Positius (_False Positive Rate_, FPR) que estan dissenyades per problemes on hi ha una classe amb més mostres que l'altra:\n",
    "\n",
    "$$ FPR = \\frac{FP}{N} = \\frac{FP}{FP+TN} $$\n",
    "<br>\n",
    "$$ TPR = \\frac{TP}{P} = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Finalment, parlarem de precisió (_precision_) i la sensibilitat (_recall_) relacionades amb les ratios de vertaders positius i vertaders negatius:\n",
    "\n",
    "$$ Precisio = \\frac{TP}{TP+FP}$$\n",
    "<br>\n",
    " $$ Sensibilitat = TPR = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Tenim una mesura que engloba aquestes mesures anteriors:\n",
    "\n",
    "$$ F1 = 2 \\frac{Precisio \\times Sensibilitat}{Precisio + Sensibilitat}$$\n",
    "\n",
    "Per sort tenim un mòdul anomenat [_metrics_](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) on hi ha totes aquestes (i d'altres) mètriques ja implementades.\n",
    "\n",
    "### Qué passa si tenim més de dues classes?\n",
    "\n",
    "Podem generalitzar el que ja sabem per a dues classes a problemes amb tres o més classes, fixem-nos en la imatge següent:\n",
    "\n",
    "![image](imatges/confusion_matrix_multi.png \"font: Researchgate\")\n",
    "\n",
    "Una de les funcions que poden ser més pràctiques en casos multi-classe serà el [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report).\n",
    "\n",
    "## Un exemple complet\n",
    "\n",
    "A continuació teniu un exemple que resumeix el procés sencer emprant la llibreria `Scikit-learn`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114   3]\n",
      " [  1  82]]\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=1, class_sep=2,\n",
    "                           random_state=5)\n",
    "\n",
    "# Tractament de les dades: Separació i estandaritzat\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenament i predicció, aquí no hi ha ajustament de paràmetres\n",
    "clf = SGDClassifier(loss=\"perceptron\", eta0=1, max_iter=1000, learning_rate=\"constant\", random_state=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "prediction = clf.predict(X_test_scaled)\n",
    "\n",
    "# Avaluacio\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(cf_matrix)\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print(\"Accuracy: \", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Ajustar el model usant una cerca exhaustiva (_Grid Search_)\n",
    "\n",
    "Els paràmetres del nostre model que podem ajustar manualment, es a dir que no són apresos de les dades d'entrenament, s'anomenen hiper-paràmetres. Ajustar el seu valor de manera intuïtiva o mitjançant successions de proves i errors pot ser una tasca llarga, per no dir impossible en el cas de models amb molts paràmetres com poden ser els _Random Forests_. O totes les combinacions possibles de **Kernel** i paràmetres associats.\n",
    "\n",
    "Existeix una tècnica de cerca exhaustiva (provar totes les combinacions de valors possibles) dels valors òptims dels hiper-paràmetres coneguda amb el nom de _Grid Search_ que ens permet automatitzar aquesta cerca penalitzant el cost temporal del procés d'entrenament.\n",
    "\n",
    "\n",
    "## Combinació de _K-Fold_ amb _Grid Search_\n",
    "\n",
    "La combinació de les dues tècniques explicades anteriorment és una de les més emprades, es coneix amb el nom de\n",
    "_nested cross-validation_. En aquest cas tenim dos bucles, un dins l'altra: el més extern en el que es divideix el conjunt\n",
    "d'entrenament usant _K-folding_ i un altre d'intern en el qual es realitza la cerca dels millors hiper-paràmetres.\n",
    "\n",
    "L'esquema que segueix és el següent:\n",
    "\n",
    "<img src=\"imatges/grid_search_k_fold.png\" width=\"600\"/>\n",
    "\n",
    "## Resum del procés complet\n",
    "\n",
    "En aquesta pràctica aplicarem l'explicat fins ara usant les eines que _Scikit_ posa al nostre abast. Les passes a seguir són:\n",
    "\n",
    "0. Creació del conjunt de dades: Possibilitat d'extracció de característiques.\n",
    "1. Separació del conjunt de dades: entrenament i test.\n",
    "2. Definició dels paràmetres per ajustar una SVM. El format de la graella de paràmetres és un diccionari on la clau és el nom del paràmetre i el valor una llista amb tots els valors a provar. [Diccionaris a Python](https://docs.python.org/3/tutorial/datastructures.html#dictionaries).\n",
    "3. Aplicar la cerca exhaustiva (_grid search_) juntament amb _k-folding_. Usarem la funció _GridSearchCV_ [enllaç](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV): `GridSearchCV(estimator, param_grid, cv=None, verbose=0)`.\n",
    "4. Entrenar amb el millor model obtingut i el conjunt d'entrenament sencer. Podem obtenir el millor model resultant de la passa anterior amb l'atribut `best_estimator_` de l'objecte `GridSearchCV`. _Nota:_ Si mirau la documentació observareu que podem obtenir altres informacions del procés de la cerca exhaustiva.\n",
    "5. Obtenir els resultats finals amb el conjunt de _test_.\n",
    "\n",
    "\n",
    "## Enunciat final de la pràctica\n",
    "\n",
    "### Dates\n",
    "- **Data d'entrega:** 19 Novembre 23:59 h\n",
    "- **Data darrera consulta:** 16 Novembre 17:20 h\n",
    "\n",
    "### Dades\n",
    "Per fer aquesta pràctica podeu elegir entre dos conjunts de dades:\n",
    "\n",
    "#### **Fashion Mnist**\n",
    "\n",
    "Aquest conjunt de dades conté 70.000 imatges en escala de grisos en 10 categories. Les imatges mostren peces de roba individuals a baixa resolució (28 per 28 píxels). Fashion MNIST està pensat com una evolució directa del conjunt de dades clàssic MNIST que conté digits escrit a mà. Utilitzarem Fashion MNIST perquè presenta un problema una mica més difícil que el MNIST normal. Tots dos conjunts de dades són relativament petits i s'utilitzen per verificar que un algorisme funciona com s'esperava. Són bons punts de partida per provar i depurar codi, el que es coneix com a _base line_. Si emprau aquest conjunt de dades, es valorarà que pogueu obtenir el millor resultat de classificació possible emprant una SVM seguint les bones pràctiques descrites en aquest document.\n",
    "\n",
    "Si elegiu aquesta pràctica la nota màxima que podeu obtenir és un 7.\n",
    "\n",
    "\n",
    "\n",
    "#### **Paisatges**\n",
    "\n",
    "Aquest conjunt de dades representa diferents paisatges o zones interiors amb 14 classes diferents. Degut a la seva dificultat, les imatges són reals sense practicament gaire pre tractament, serà necessari extreure característiques de les imatges per millorar els resultats. Per exemple els [HOG](https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html).\n",
    "\n",
    "Si elegiu aquesta pràctica la nota màxima que podeu obtenir és un 10.\n",
    "\n",
    "Trobareu els dos conjunts de dades en la carpeta **dat**.\n",
    "\n",
    "### Instruccions\n",
    "\n",
    "- La pràctica es pot realitzar tant per parelles com de forma individual.\n",
    "- La solució sempre implicará cercar la millor parametrització d'una SVM seguint les bones pràctiques previament descrites.\n",
    "- Es realitzarà un seguiment de les evolucions de la pràctica durant les sessions dels dijous. Si no es realitza aquest seguiment setmanal, el professor es reserva el dret de realitzar entrevistes individualitzades per validar els coneixements de l'alumne.\n",
    "- Dues pràctiques similars seran considerades plagi.\n",
    "- Una pràctica de la qual no es pugui explicar alguna part serà considerada suspesa.\n",
    "- L'entrega de la pràctica consistirà en:\n",
    "    - Un informe **tècnic** en format _pdf_. Tant es pot fer emprant _jupyter notebooks_ com _latex_ com altres processadors de text més convencionals. Ha de tenir la següent estructura:\n",
    "      1. Introducció al problema que es vol resoldre: Que i com.\n",
    "      2. Tractament de les dades.\n",
    "      3. Experiments realitzats: descripció de cada experiment i resultats obtinguts.\n",
    "      4. Anàlisi dels resultats i conclusions.\n",
    "      5. En el cas de ser una parella, explicar quines tasques ha realitzat cada un dels membres.\n",
    "\n",
    "    - Una carpeta comprimida amb tot el codi font que permeti reproduir els experiments realitzats.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
